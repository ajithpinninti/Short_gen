{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# audio_processor.py\n",
    "#############################\n",
    "import os\n",
    "import whisper\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from utils import time_to_seconds\n",
    "import re\n",
    "import pickle\n",
    "CACHE_FILE = \"processed_result_cache.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_with_timestamps(audio_path):\n",
    "    \"\"\"Convert audio to text with word-level timestamps using Whisper\"\"\"\n",
    "    print(\"loading speech to text model ....    \")\n",
    "    #model = whisper.load_model(\"medium\")\n",
    "    print(\"speech to text model running ....    \")\n",
    "\n",
    "    ####################Cache the processed audio####################\n",
    "    # Check if cached audio exists\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        print(\"Loading cached processed_audio...\")\n",
    "        with open(CACHE_FILE, \"rb\") as f:\n",
    "            result = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Processing audio and caching the result...\")\n",
    "        model = whisper.load_model(\"medium\")\n",
    "        result = model.transcribe(audio_path, fp16=False, word_timestamps=True)\n",
    "\n",
    "    # Save to cache\n",
    "    with open(CACHE_FILE, \"wb\") as f:\n",
    "        pickle.dump(result, f)\n",
    "    ###############################################################       \n",
    "    return result[\"segments\"]\n",
    "\n",
    "def align_script_with_audio(script_path, audio_segments):\n",
    "    \"\"\"\n",
    "    Aligns the original script with the audio transcription.\n",
    "    This function reads a script from a file and aligns it with the provided audio segments.\n",
    "    It ensures that each word in the script corresponds to a word in the audio segments.\n",
    "    Args:\n",
    "        script_path (str): The file path to the script.\n",
    "        audio_segments (list): A list of dictionaries, where each dictionary represents an audio segment\n",
    "                               and contains 'words' (a list of word dictionaries with 'word', 'start', and 'end' keys),\n",
    "                               'text' (the transcribed text of the segment), 'start' (start time of the segment),\n",
    "                               and 'end' (end time of the segment).\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains:\n",
    "              - 'script_line' (str): A line from the script.\n",
    "              - 'words' (list): A list of word dictionaries with 'text', 'start', and 'end' keys.\n",
    "              - 'start' (float): The start time of the segment.\n",
    "              - 'end' (float): The end time of the segment.\n",
    "    Raises:\n",
    "        ValueError: If the number of words in the audio segments does not match the number of words in the script.\n",
    "    \"\"\"\n",
    "    with open(script_path, encoding=\"utf-8\") as f:\n",
    "        script_lines = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # converting audio_segments into list of words ####\n",
    "    audio_words = []\n",
    "    for segment in audio_segments:\n",
    "        audio_words += segment['words']\n",
    "    ######################################################\n",
    "    script = {}\n",
    "    script[\"script_lines\"] = script_lines\n",
    "    script[\"script_len\"] = len(script_lines)\n",
    "    script[\"script_line_words\"] = []\n",
    "    script[\"script_all_words\"] = []\n",
    "    for text in script_lines:\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text) #removing all special characters\n",
    "        script[\"script_all_words\"] += re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", text)\n",
    "        script[\"script_line_words\"].append(re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", text))\n",
    "        # todo: change the text in evry word object in segment ( later)\n",
    "\n",
    "    # checking the number of audio_words and script_lines words\n",
    "    if ( len(audio_words) == len( script['script_all_words']) ):\n",
    "        #iterate through every segment word and replace with script word\n",
    "        word_ind = 0\n",
    "        # audio_segments\n",
    "        for idx,segment in enumerate(audio_segments):\n",
    "            if idx >= script['script_len']:\n",
    "                audio_segments = audio_segments[0:idx]\n",
    "                break\n",
    "            \n",
    "            segment['text'] = script['script_lines'][idx]\n",
    "            segment['words'] = audio_words[\n",
    "                word_ind:len(script['script_line_words'][idx]) + word_ind\n",
    "            ]\n",
    "            word_ind += len(script['script_line_words'][idx])\n",
    "            # for seg_word in  script['script_line_words'][idx] :\n",
    "            #     seg_word = script['script_line_words'][word_ind]\n",
    "            #     word_ind+=1\n",
    "            segment['start'] = segment['words'][0]['start']\n",
    "            segment['end'] = segment['words'][-1]['end']\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"#########Number of words in audio and script are not equal#########3\")\n",
    "        return\n",
    "\n",
    "    aligned_data = []\n",
    "    for idx, segment in enumerate(audio_segments):\n",
    "        if idx >= len(script_lines):\n",
    "            break\n",
    "        words = []\n",
    "        for word in segment['words']:\n",
    "            words.append({\n",
    "                'text': word['word'],\n",
    "                'start': word['start'],\n",
    "                'end': word['end']\n",
    "            })\n",
    "        \n",
    "        aligned_data.append({\n",
    "            'script_line': script_lines[idx],\n",
    "            'words': words,\n",
    "            'start': segment['start'],\n",
    "            'end': segment['end']\n",
    "        })\n",
    "    \n",
    "    return aligned_data\n",
    "\n",
    "def process_audio(audio_path, script_path):\n",
    "    \"\"\"Main audio processing function\"\"\"\n",
    "    print(\"Processing audio...\")\n",
    "    audio_segments = transcribe_with_timestamps(audio_path)\n",
    "    aligned_data = align_script_with_audio(script_path, audio_segments)\n",
    "    print(\"audio process is completed\")\n",
    "    return {\n",
    "        'raw_audio': AudioFileClip(audio_path),\n",
    "        'aligned_data': aligned_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# video_processor.py (Updated for MoviePy 2.1.1)\n",
    "#############################\n",
    "from moviepy.video.VideoClip import ImageClip, TextClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import concatenate_videoclips\n",
    "import os\n",
    "\n",
    "def create_image_clips(image_dir, aligned_data):\n",
    "    \"\"\"Create image clips with proper sequencing and duration\"\"\"\n",
    "    images = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)], \n",
    "                   key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "    \n",
    "    clips = []\n",
    "    test_start = [0,4.56,9.82,6]\n",
    "    test_durations = [4.2,4.58,2.44]\n",
    "    for idx, segment in enumerate(aligned_data):\n",
    "        if idx >= len(images):\n",
    "            break\n",
    "            \n",
    "        # clip = ImageClip(images[idx]).with_start(test_start[idx],change_end=True)\n",
    "        # clip = clip.with_duration(test_durations[idx])\n",
    "        duration = segment['end'] - segment['start']        \n",
    "        print(f\"Segment {idx}: Start={segment['start']}, End={segment['end']}, Duration={duration}\")\n",
    "        clip = ImageClip(images[idx]).with_start(segment['start'],change_end=False)\n",
    "        if(idx == len(aligned_data)-1):\n",
    "            #final clip end with last segment end\n",
    "            clip = clip.with_end(segment['end'])\n",
    "        else:\n",
    "            #clip end with next segment start\n",
    "            clip = clip.with_end(aligned_data[idx+1]['start'])\n",
    "        \n",
    "        # clip = clip.with_duration(segment['end'] - segment['start'])\n",
    "        print(f\"Clip {idx} duration after assignment: {clip.duration}\")\n",
    "        print(f\"Clip {idx} start  after assignment: {clip.start}\")\n",
    "        print(f\"Clip {idx} end  after assignment: {clip.end}\")\n",
    "\n",
    "\n",
    "        # clip.preview(fps=24)\n",
    "        # print(\"clip duration\")\n",
    "        # print(idx)\n",
    "        # print(clip.duration)\n",
    "        clips.append(clip)  #set_start(segment['start']))\n",
    "    \n",
    "    return concatenate_videoclips(clips, method=\"chain\")#\"chain\")\n",
    "\n",
    "def create_subtitles(aligned_data, sub_position):\n",
    "    \"\"\"Generate animated word-level subtitles\"\"\"\n",
    "    subtitle_clips = []\n",
    "    font_name = r\"fonts\\Arial.otf\"\n",
    "    for segment in aligned_data:\n",
    "        words = segment['words']\n",
    "        \n",
    "        for word in words:\n",
    "            txt_clip = TextClip(\n",
    "                text=word['text'],\n",
    "                font_size=70,\n",
    "                font=font_name,\n",
    "                color='white',\n",
    "                stroke_color='black',\n",
    "                stroke_width=2\n",
    "            ).with_start(word['start']).with_duration(word['end'] - word['start'])\n",
    "            \n",
    "            txt_clip = txt_clip.with_position(('center', sub_position))\n",
    "            # txt_clip.preview(fps=24)\n",
    "            subtitle_clips.append(txt_clip)\n",
    "    \n",
    "    return subtitle_clips\n",
    "\n",
    "def process_video(image_dir, script_path, audio_data, output_path, sub_position):\n",
    "    \"\"\"Main video processing function\"\"\"\n",
    "    video_clip = create_image_clips(image_dir, audio_data['aligned_data'])\n",
    "    # video_clip.preview(fps=24)\n",
    "    subtitles = create_subtitles(audio_data['aligned_data'], sub_position)\n",
    "    \n",
    "    final_video = CompositeVideoClip([video_clip] + subtitles)\n",
    "    # final_video.preview(fps=24)\n",
    "    final_video = final_video.with_audio(audio_data['raw_audio'])\n",
    "    # final_video.preview(fps=24)\n",
    "    \n",
    "    final_video.write_videofile(\n",
    "        output_path,\n",
    "        codec='libx264',\n",
    "        audio_codec='aac',\n",
    "        fps=24,\n",
    "        threads=4,\n",
    "        preset='fast'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"Test_data/images\"\n",
    "script_path = \"Test_data/dronacharya killed/Script/script.txt\"\n",
    "audio_path = \"Test_data/dronacharya killed/audio/script.mp3\"\n",
    "output = \"final_video.mp4\"\n",
    "sub_pos = 30\n",
    "\n",
    "processed_audio = process_audio(audio_path, script_path)\n",
    "process_video(image_dir, script_path, processed_audio,\n",
    "                output, sub_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
