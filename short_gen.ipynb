{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# audio_processor.py\n",
    "#############################\n",
    "import os\n",
    "import whisper\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from utils import time_to_seconds\n",
    "import re\n",
    "import pickle\n",
    "CACHE_FILE = \"processed_result_cache.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_with_timestamps(audio_path):\n",
    "    \"\"\"Convert audio to text with word-level timestamps using Whisper\"\"\"\n",
    "    print(\"loading speech to text model ....    \")\n",
    "    #model = whisper.load_model(\"medium\")\n",
    "    print(\"speech to text model running ....    \")\n",
    "\n",
    "    ####################Cache the processed audio####################\n",
    "    # Check if cached audio exists\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        print(\"Loading cached processed_audio...\")\n",
    "        with open(CACHE_FILE, \"rb\") as f:\n",
    "            result = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Processing audio and caching the result...\")\n",
    "        model = whisper.load_model(\"medium\")\n",
    "        result = model.transcribe(audio_path, fp16=False, word_timestamps=True)\n",
    "\n",
    "    # Save to cache\n",
    "    with open(CACHE_FILE, \"wb\") as f:\n",
    "        pickle.dump(result, f)\n",
    "    ###############################################################       \n",
    "    return result[\"segments\"]\n",
    "\n",
    "def align_script_with_audio(script_path, audio_segments):\n",
    "    \"\"\"\n",
    "    Aligns the original script with the audio transcription.\n",
    "    This function reads a script from a file and aligns it with the provided audio segments.\n",
    "    It ensures that each word in the script corresponds to a word in the audio segments.\n",
    "    Args:\n",
    "        script_path (str): The file path to the script.\n",
    "        audio_segments (list): A list of dictionaries, where each dictionary represents an audio segment\n",
    "                               and contains 'words' (a list of word dictionaries with 'word', 'start', and 'end' keys),\n",
    "                               'text' (the transcribed text of the segment), 'start' (start time of the segment),\n",
    "                               and 'end' (end time of the segment).\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains:\n",
    "              - 'script_line' (str): A line from the script.\n",
    "              - 'words' (list): A list of word dictionaries with 'text', 'start', and 'end' keys.\n",
    "              - 'start' (float): The start time of the segment.\n",
    "              - 'end' (float): The end time of the segment.\n",
    "    Raises:\n",
    "        ValueError: If the number of words in the audio segments does not match the number of words in the script.\n",
    "    \"\"\"\n",
    "    with open(script_path, encoding=\"utf-8\") as f:\n",
    "        script_lines = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # converting audio_segments into list of words ####\n",
    "    audio_words = []\n",
    "    for segment in audio_segments:\n",
    "        audio_words += segment['words']\n",
    "    ######################################################\n",
    "    script = {}\n",
    "    script[\"script_lines\"] = script_lines\n",
    "    script[\"script_len\"] = len(script_lines)\n",
    "    script[\"script_line_words\"] = []\n",
    "    script[\"script_all_words\"] = []\n",
    "    for text in script_lines:\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text) #removing all special characters\n",
    "        script[\"script_all_words\"] += re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", text)\n",
    "        script[\"script_line_words\"].append(re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", text))\n",
    "        # todo: change the text in evry word object in segment ( later)\n",
    "\n",
    "    # checking the number of audio_words and script_lines words\n",
    "    if ( len(audio_words) == len( script['script_all_words']) ):\n",
    "        #iterate through every segment word and replace with script word\n",
    "        word_ind = 0\n",
    "        # audio_segments\n",
    "        for idx,segment in enumerate(audio_segments):\n",
    "            if idx >= script['script_len']:\n",
    "                audio_segments = audio_segments[0:idx]\n",
    "                break\n",
    "            \n",
    "            segment['text'] = script['script_lines'][idx]\n",
    "            segment['words'] = audio_words[\n",
    "                word_ind:len(script['script_line_words'][idx]) + word_ind\n",
    "            ]\n",
    "            word_ind += len(script['script_line_words'][idx])\n",
    "            # for seg_word in  script['script_line_words'][idx] :\n",
    "            #     seg_word = script['script_line_words'][word_ind]\n",
    "            #     word_ind+=1\n",
    "            segment['start'] = segment['words'][0]['start']\n",
    "            segment['end'] = segment['words'][-1]['end']\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"#########Number of words in audio and script are not equal#########3\")\n",
    "        return\n",
    "\n",
    "    aligned_data = []\n",
    "    for idx, segment in enumerate(audio_segments):\n",
    "        if idx >= len(script_lines):\n",
    "            break\n",
    "        words = []\n",
    "        for word in segment['words']:\n",
    "            words.append({\n",
    "                'text': word['word'],\n",
    "                'start': word['start'],\n",
    "                'end': word['end']\n",
    "            })\n",
    "        \n",
    "        aligned_data.append({\n",
    "            'script_line': script_lines[idx],\n",
    "            'words': words,\n",
    "            'start': segment['start'],\n",
    "            'end': segment['end']\n",
    "        })\n",
    "    \n",
    "    return aligned_data\n",
    "\n",
    "def process_audio(audio_path, script_path):\n",
    "    \"\"\"Main audio processing function\"\"\"\n",
    "    print(\"Processing audio...\")\n",
    "    audio_segments = transcribe_with_timestamps(audio_path)\n",
    "    aligned_data = align_script_with_audio(script_path, audio_segments)\n",
    "    print(\"audio process is completed\")\n",
    "    return {\n",
    "        'raw_audio': AudioFileClip(audio_path),\n",
    "        'aligned_data': aligned_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# video_processor.py (Updated for MoviePy 2.1.1)\n",
    "#############################\n",
    "from moviepy.video.VideoClip import ImageClip, TextClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import concatenate_videoclips\n",
    "import os\n",
    "\n",
    "def create_image_clips(image_dir, aligned_data):\n",
    "    \"\"\"Create image clips with proper sequencing and duration\"\"\"\n",
    "    images = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)], \n",
    "                   key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "    \n",
    "    clips = []\n",
    "    test_start = [0,4.56,9.82,6]\n",
    "    test_durations = [4.2,4.58,2.44]\n",
    "    for idx, segment in enumerate(aligned_data):\n",
    "        if idx >= len(images):\n",
    "            break\n",
    "            \n",
    "        # clip = ImageClip(images[idx]).with_start(test_start[idx],change_end=True)\n",
    "        # clip = clip.with_duration(test_durations[idx])\n",
    "        duration = segment['end'] - segment['start']        \n",
    "        print(f\"Segment {idx}: Start={segment['start']}, End={segment['end']}, Duration={duration}\")\n",
    "        clip = ImageClip(images[idx]).with_start(segment['start'],change_end=False)\n",
    "        if(idx == len(aligned_data)-1):\n",
    "            #final clip end with last segment end\n",
    "            clip = clip.with_end(segment['end'])\n",
    "        else:\n",
    "            #clip end with next segment start\n",
    "            clip = clip.with_end(aligned_data[idx+1]['start'])\n",
    "        \n",
    "        # clip = clip.with_duration(segment['end'] - segment['start'])\n",
    "        # print(f\"Clip {idx} duration after assignment: {clip.duration}\")\n",
    "        # print(f\"Clip {idx} start  after assignment: {clip.start}\")\n",
    "        # print(f\"Clip {idx} end  after assignment: {clip.end}\")\n",
    "\n",
    "\n",
    "        # clip.preview(fps=24)\n",
    "        # print(\"clip duration\")\n",
    "        # print(idx)\n",
    "        # print(clip.duration)\n",
    "        clips.append(clip)  #set_start(segment['start']))\n",
    "    \n",
    "    return concatenate_videoclips(clips, method=\"chain\")#\"chain\")\n",
    "\n",
    "def create_subtitles(aligned_data, sub_position):\n",
    "    \"\"\"Generate animated word-level subtitles\"\"\"\n",
    "    subtitle_clips = []\n",
    "    font_name = r\"fonts\\Arial.otf\"\n",
    "    for segment in aligned_data:\n",
    "        words = segment['words']\n",
    "        \n",
    "        for word in words:\n",
    "            txt_clip = TextClip(\n",
    "                text=word['text'],\n",
    "                font_size=70,\n",
    "                font=font_name,\n",
    "                color='white',\n",
    "                stroke_color='black',\n",
    "                stroke_width=2\n",
    "            ).with_start(word['start']).with_duration(word['end'] - word['start'])\n",
    "            \n",
    "            txt_clip = txt_clip.with_position(('center', sub_position))\n",
    "            # txt_clip.preview(fps=24)\n",
    "            subtitle_clips.append(txt_clip)\n",
    "    \n",
    "    return subtitle_clips\n",
    "\n",
    "def process_video(image_dir, script_path, audio_data, output_path, sub_position):\n",
    "    \"\"\"Main video processing function\"\"\"\n",
    "    video_clip = create_image_clips(image_dir, audio_data['aligned_data'])\n",
    "    # video_clip.preview(fps=24)\n",
    "    subtitles = create_subtitles(audio_data['aligned_data'], 'center') #sub_position)#change here\n",
    "    \n",
    "    final_video = CompositeVideoClip([video_clip] + subtitles)\n",
    "    # final_video.preview(fps=24)\n",
    "    final_video = final_video.with_audio(audio_data['raw_audio'])\n",
    "    # final_video = final_video.with_speed_scaled(1.5)\n",
    "    # final_video.preview(fps=24)\n",
    "    \n",
    "    final_video.write_videofile(\n",
    "        output_path,\n",
    "        codec='libx264',\n",
    "        audio_codec='aac',\n",
    "        fps=24,\n",
    "        threads=4,\n",
    "        preset='fast'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio...\n",
      "loading speech to text model ....    \n",
      "speech to text model running ....    \n",
      "Loading cached processed_audio...\n",
      "audio process is completed\n",
      "Segment 0: Start=0.0, End=4.2, Duration=4.2\n",
      "Segment 1: Start=4.56, End=9.14, Duration=4.580000000000001\n",
      "Segment 2: Start=9.82, End=12.26, Duration=2.4399999999999995\n",
      "Segment 3: Start=12.26, End=15.12, Duration=2.8599999999999994\n",
      "Segment 4: Start=16.16, End=21.08, Duration=4.919999999999998\n",
      "Segment 5: Start=21.54, End=28.8, Duration=7.260000000000002\n",
      "Segment 6: Start=29.52, End=34.74, Duration=5.220000000000002\n",
      "Segment 7: Start=35.38, End=41.02, Duration=5.640000000000001\n",
      "Segment 8: Start=41.78, End=46.0, Duration=4.219999999999999\n",
      "MoviePy - Building video final_video.mp4.\n",
      "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video final_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready final_video.mp4\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"Test_data/images\"\n",
    "script_path = \"Test_data/dronacharya killed/Script/script.txt\"\n",
    "audio_path = \"Test_data/dronacharya killed/audio/script.mp3\"\n",
    "output = \"final_video.mp4\"\n",
    "sub_pos = 30\n",
    "\n",
    "processed_audio = process_audio(audio_path, script_path)\n",
    "process_video(image_dir, script_path, processed_audio,\n",
    "                output, sub_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from utils import time_to_seconds\n",
    "import re\n",
    "import pickle\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "    temp_path = temp_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in C:\\Users\\ajitp\\AppData\\Local\\Temp\\tmphsk2kzg6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "audio_path = \"Test_data/dronacharya killed/audio/script.mp3\"\n",
    "original_audio = AudioFileClip(audio_path)\n",
    "sped_up_audio = original_audio.with_speed_scaled(1.25) #speedx(factor=1.25)\n",
    "sped_up_audio.write_audiofile(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def speed_up_video(input_file, output_file, speed_factor):\n",
    "    # Extract audio from video\n",
    "    temp_audio = \"temp_audio.wav\"\n",
    "    os.system(f'ffmpeg -i \"{input_file}\" -q:a 0 -map a \"{temp_audio}\" -y')\n",
    "\n",
    "    # Apply time stretching using rubberband\n",
    "    processed_audio = \"processed_audio.wav\"\n",
    "    os.system(f\"rubberband -t {speed_factor} {temp_audio} {processed_audio}\")\n",
    "\n",
    "    # Speed up the video without audio\n",
    "    temp_video = \"temp_video.mp4\"\n",
    "    os.system(f'ffmpeg -i \"{input_file}\" -filter:v \"setpts={1/speed_factor}*PTS\" \"{temp_video}\" -y')\n",
    "\n",
    "    # Merge new audio with video\n",
    "    os.system(f'ffmpeg -i \"{temp_video}\" -i \"{processed_audio}\" -c:v copy -c:a aac -strict experimental \"{output_file}\" -y')\n",
    "\n",
    "    # Cleanup temp files\n",
    "    os.remove(temp_audio)\n",
    "    os.remove(processed_audio)\n",
    "    os.remove(temp_video)\n",
    "\n",
    "    print(f\"Processed video saved as: {output_file}\")\n",
    "\n",
    "# Example Usage:\n",
    "input_video = \"input.mp4\"\n",
    "output_video = \"output.mp4\"\n",
    "speed_factor = 1.5  # Increase speed by 1.5x\n",
    "\n",
    "speed_up_video(input_video, output_video, speed_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\ajitp\\AppData\\Local\\Temp\\ipykernel_15776\\3346408553.py:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  input_file = \"Test_data\\aswathama killed\\audio\\script.mp3\"  # Replace with your input file path\n",
      "C:\\Users\\ajitp\\AppData\\Local\\Temp\\ipykernel_15776\\3346408553.py:24: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  input_file = \"Test_data\\aswathama killed\\audio\\script.mp3\"  # Replace with your input file path\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mincrease_speed_without_pitch_change_librosa\u001b[39m(input_file, output_file, speed_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.25\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def increase_speed_without_pitch_change_librosa(input_file, output_file, speed_factor=1.25):\n",
    "    \"\"\"\n",
    "    Increase the speed of an audio file without changing its pitch using librosa.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input audio file.\n",
    "        output_file (str): Path to save the output audio file.\n",
    "        speed_factor (float): Speed multiplier (e.g., 1.25 for 1.25x speed).\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Time-stretch the audio\n",
    "    y_stretched = librosa.effects.time_stretch(y, rate=speed_factor)\n",
    "    \n",
    "    # Save the result\n",
    "    sf.write(output_file, y_stretched, sr)\n",
    "    print(f\"Audio saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = \"Test_data\\aswathama killed\\audio\\script.mp3\"  # Replace with your input file path\n",
    "output_file = \"voiceover_fast_librosa.wav\"  # Replace with your desired output file path\n",
    "increase_speed_without_pitch_change_librosa(input_file, output_file, speed_factor=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to voiceover_fast.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import os\n",
    "\n",
    "def increase_speed_without_pitch_change(input_file, output_file, speed_factor=1.5):\n",
    "    \"\"\"\n",
    "    Increase the speed of an audio file without changing its pitch.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input audio file.\n",
    "        output_file (str): Path to save the output audio file.\n",
    "        speed_factor (float): Speed multiplier (e.g., 1.25 for 1.25x speed).\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    \n",
    "    # Time-stretch the audio (speed up without changing pitch)\n",
    "    stretched_audio = audio.speedup(playback_speed=speed_factor)\n",
    "    \n",
    "    # Export the result\n",
    "    stretched_audio.export(output_file, format=\"wav\")\n",
    "    print(f\"Audio saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = \"Test_data/dronacharya killed/audio/script.mp3\"  # Replace with your input file path\n",
    "output_file = \"voiceover_fast.wav\"  # Replace with your desired output file path\n",
    "increase_speed_without_pitch_change(input_file, output_file, speed_factor=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.video.fx.all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m speedx  \u001b[38;5;66;03m# Import the speedx effect\u001b[39;00m\n",
      "\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_video\u001b[39m(image_dir, script_path, audio_data, output_path, sub_position, speed_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Main video processing function with speed change applied only to the final composite clip.\"\"\"\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.video.fx.all'"
     ]
    }
   ],
   "source": [
    "from moviepy.video.fx.all import speedx  # Import the speedx effect\n",
    "\n",
    "def process_video(image_dir, script_path, audio_data, output_path, sub_position, speed_factor=1.0):\n",
    "    \"\"\"Main video processing function with speed change applied only to the final composite clip.\"\"\"\n",
    "    # Create the video clip and subtitles as before (no speed changes here)\n",
    "    video_clip = create_image_clips(image_dir, audio_data['aligned_data'])\n",
    "    subtitles = create_subtitles(audio_data['aligned_data'], sub_position)\n",
    "    \n",
    "    # Composite the video clip with the subtitles and audio\n",
    "    final_video = CompositeVideoClip([video_clip] + subtitles)\n",
    "    final_video = final_video.with_audio(audio_data['raw_audio'])\n",
    "    \n",
    "    # Apply the speed change to the final composite video clip only\n",
    "    final_video = final_video.fx(speedx, speed_factor)\n",
    "    \n",
    "    # Write out the final video file (use a fixed fps or adjust if needed)\n",
    "    final_video.write_videofile(\n",
    "        output_path,\n",
    "        codec='libx264',\n",
    "        audio_codec='aac',\n",
    "        fps=24,\n",
    "        threads=4,\n",
    "        preset='fast'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.video.fx.all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m speedx  \u001b[38;5;66;03m# Import the speedx effect\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_video\u001b[39m(image_dir, script_path, audio_data, output_path, sub_position, speed_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Main video processing function with speed change applied only to the final composite clip.\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.video.fx.all'"
     ]
    }
   ],
   "source": [
    "from moviepy.video.fx.all import speedx  # Import the speedx effect\n",
    "\n",
    "def process_video(image_dir, script_path, audio_data, output_path, sub_position, speed_factor=1.0):\n",
    "    \"\"\"Main video processing function with speed change applied only to the final composite clip.\"\"\"\n",
    "    # Create the video clip and subtitles as before (no speed changes here)\n",
    "    video_clip = create_image_clips(image_dir, audio_data['aligned_data'])\n",
    "    subtitles = create_subtitles(audio_data['aligned_data'], sub_position)\n",
    "    \n",
    "    # Composite the video clip with the subtitles and audio\n",
    "    final_video = CompositeVideoClip([video_clip] + subtitles)\n",
    "    final_video = final_video.with_audio(audio_data['raw_audio'])\n",
    "    \n",
    "    # Apply the speed change to the final composite video clip only\n",
    "    final_video = final_video.fx(speedx, speed_factor)\n",
    "    \n",
    "    # Write out the final video file (use a fixed fps or adjust if needed)\n",
    "    final_video.write_videofile(\n",
    "        output_path,\n",
    "        codec='libx264',\n",
    "        audio_codec='aac',\n",
    "        fps=24,\n",
    "        threads=4,\n",
    "        preset='fast'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
